{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安裝 selenium \n",
    "selenium : 網⾴⾃動化測試⼯具    \n",
    "\n",
    "在jupyter輸入: !pip install selenium\n",
    "\n",
    "執行後:       \n",
    "Requirement already satisfied: selenium in c:\\program files\\python37\\lib\\site-packages (3.141.0) \n",
    "Requirement already satisfied: urllib3 in c:\\program files\\python37\\lib\\site-packages (from selenium) (1.25.2)             \n",
    "\n",
    "BUT site-packages 會下載到c:\\program files\\python37\\lib    #python37           \n",
    "=> 要copy到 C:\\Users\\aduser01\\Anaconda3\\Lib                #Anaconda3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('C:/Users/aduser01/chromedriver.exe')\n",
    "driver.get('https://www.google.com')\n",
    "\n",
    "driver.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# => 成功進入跳轉後的網頁!!!\n",
    "from selenium import webdriver\n",
    "import time\n",
    "driver = webdriver.Chrome('C:/Users/aduser01/chromedriver.exe')\n",
    "driver.get('https://www.com.tw/cross/check_001012_NO_1_108_0_3.html')\n",
    "time.sleep(5)  #since the website will delay 5 seconds\n",
    "html = driver.page_source\n",
    "#print(html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*查找元素 - selenium\n",
    "find_element: return the first object     \n",
    "find_elements: return a 'list' containg all the objects      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "108年大學 | 科大四技申請[學測]交叉查榜 - 依校系榜單查詢        \n",
      "1\n",
      "108年大學 | 科大四技申請[學測]交叉查榜 - 依校系榜單查詢        \n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "s = driver.find_elements_by_class_name('homepagetitle')\n",
    "print(len(s))  #how many is found\n",
    "print(s[0].text)\n",
    "\n",
    "x = driver.find_elements_by_xpath('//*[@class=\"homepagetitle\"]')\n",
    "print(len(x)) \n",
    "print(x[0].text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "大學繁星推薦\n",
      "大學指考\n",
      "交叉查榜[學測]\n",
      "落點分析\n",
      "四技甄選[統測]\n",
      "四技分發[統測]\n",
      "歷屆試題\n",
      "升學官網\n"
     ]
    }
   ],
   "source": [
    "t = driver.find_elements_by_class_name('navigation')\n",
    "print(len(t)) \n",
    "print(t[0].text)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 網頁原始碼\n",
    "<ul class=\"navigation\">\n",
    "  <li><a href=\"#\">大學繁星推薦</a>...\n",
    "    <ul>\n",
    "      <li><a href=\"#\">108年</a>\n",
    "        <ul>\n",
    "          <li><a href=\"../star/\">依校系查榜</a></li>\n",
    "          <li><a href=\"../star/uncontinuequery108.html\">准考證批次查</a></li>\n",
    "          <li><a href=\"../star/test_county108.html\">依考區查榜</a></li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li><a href=\"#\">107年</a>\n",
    "        ...\n",
    "        </ul>\n",
    "      </li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><a href=\"#\">大學指考</a>\n",
    "    ...\n",
    "    \n",
    "len(t) == 1: 只找到一組class=\"navigation\" \n",
    "只選擇/找出這一組之最先找到的層級的elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = driver.find_elements_by_xpath('//title')  #return list\n",
    "print(len(x))\n",
    "print(x[0].text)  #讀到空白"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***-------------------------------------------------------------------------------------------------------------------------------***\n",
    "### crawler - 學測 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. dep_id_108_fin\n",
    "寫入dep_id_108.csv => 整理成 final_output/dep_id_108.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depCode_list\n",
    "f1 = open(\"crawler_output/dep_id_108.csv\", 'a', encoding=\"utf-8\") \n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "driver = webdriver.Chrome('C:/Users/aduser01/chromedriver.exe')\n",
    "\n",
    "schoolCode_list = ['001','002','003','004','005','006','007','008','009','011','012','013','014','015','016','017','018','019','020','021','022','023','025','026','027','028','030','031','032','033','034','035','036','038','039','040','041','042','043','045','046','047','050','051','056','058','059','060','063','065','079','099','100','101','108','109','110','111','113','130','132','133','134','150','151','152','153','154']\n",
    "for schoolCode in schoolCode_list:\n",
    "    driver.get('https://www.com.tw/cross/university_%s_108.html'% (schoolCode))\n",
    "    time.sleep(5)  #since the website will delay 5 seconds\n",
    "    #html = driver.page_source\n",
    "    \n",
    "    schoolName = driver.find_element_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr/td[3]') #校名\n",
    "    dep = driver.find_elements_by_xpath(\"//div[@id='university_dep_row_height']\")  #系所代碼 & 系所名稱 & '交叉查榜 & '已放榜'\n",
    "    for i in range(len(dep)):\n",
    "        if i % 4 == 0:  #系所代碼\n",
    "            f1.write(\"%s%s%s%s\" % (schoolCode,',',schoolName.text,',')) #學校代碼  #校名\n",
    "            str = dep[i].text[1:7]              #系所代碼\n",
    "            #print(str)\n",
    "            f1.write(\"%s%s\" % (str,',')) \n",
    "        if i % 4 == 1:               #系所名稱\n",
    "            str = dep[i].text\n",
    "            f1.write(\"%s\\n\" % (str)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 學生108_fin\n",
    "each 學生資料、正備取、最終選擇之學校"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#學生資料 正備取 最終選擇之學校\n",
    "f2 = open(\"crawler_output/學生108-12.csv\", 'a', encoding=\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "uname = pd.read_csv(\"final_output/dep_id_108.csv\", encoding=\"utf-8\", dtype=str)\n",
    "depCode_list = uname['dep_id']\n",
    "print(len(depCode_list))  #2009\n",
    "\n",
    "print(depCode_list[2015])  #134302\n",
    "depCode_list = depCode_list[1996:]\n",
    "print(depCode_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/aduser01/chromedriver.exe')\n",
    "\n",
    "for depCode in depCode_list:\n",
    "    driver.get('https://www.com.tw/cross/check_%s_NO_1_108_0_3.html'% (depCode))\n",
    "    time.sleep(5)  #the first time: since the website will delay 5 seconds\n",
    "    #html = driver.page_source\n",
    "    \n",
    "    print(depCode)\n",
    "    ## for each dep.\n",
    "    for_apply_stu_count = driver.find_elements_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr')\n",
    "    dep_apply_stu_count = len(for_apply_stu_count)-4  #64 students\n",
    "    school_id = driver.find_element_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr')\n",
    "    school_id = school_id.text[4:10]\n",
    "\n",
    "    #for each student who applys the dep.\n",
    "    state = driver.find_elements_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr/td[2]')  #正備取\n",
    "    temp = driver.find_elements_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr/td[3]')  \n",
    "\n",
    "    name = driver.find_elements_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr/td[4]')  #姓名\n",
    "\n",
    "\n",
    "    for i in range(1,dep_apply_stu_count+1):  #0~63 range(dep_apply_stu_count)\n",
    "        if temp[i].text[0] == '8':\n",
    "            stu_code = temp[i].text[0:6] \n",
    "        else:\n",
    "            stu_code = temp[i].text[0:8]         #學生代碼 \n",
    "        exam_loc = temp[i].text[14:]      #考區  \n",
    "        #print(stu_code)\n",
    "        f2.write(\"%s,%s,%s,%s,%s\\n\" % (school_id, stu_code, name[i].text, state[i].text , exam_loc)) \n",
    "\n",
    "    #print(len(state))\n",
    "    #print(len(temp))\n",
    "    #print(len(name))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 選擇學校108_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open(\"crawler_output/選擇學校108fin.csv\", 'a', encoding=\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898    110012\n",
      "1899    110022\n",
      "1900    110032\n",
      "1901    110042\n",
      "1902    110052\n",
      "1903    110062\n",
      "1904    110072\n",
      "1905    110082\n",
      "1906    110092\n",
      "1907    110102\n",
      "1908    110112\n",
      "1909    110122\n",
      "1910    110132\n",
      "1911    110142\n",
      "1912    110152\n",
      "1913    110162\n",
      "1914    110172\n",
      "1915    110182\n",
      "1916    110192\n",
      "Name: dep_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "uname = pd.read_csv(\"final_output/dep_id_108.csv\") # encoding=\"utf-8\", dtype=str\n",
    "\n",
    "depCode_list = uname['dep_id']\n",
    "#print(len(depCode_list))  #2103\n",
    "print(depCode_list[1898:1917]) \n",
    "depCode_list = depCode_list[1898:1917]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#寫入.xlsx檔\n",
    "from openpyxl import Workbook\n",
    "wb = Workbook()\n",
    "sheet = wb.active "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110012\n",
      "110022\n",
      "110032\n",
      "110042\n",
      "110052\n",
      "110062\n",
      "110072\n",
      "110082\n",
      "110092\n",
      "110102\n",
      "110112\n",
      "110122\n",
      "110132\n",
      "110142\n",
      "110152\n",
      "110162\n",
      "110172\n",
      "110182\n",
      "110192\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "driver = webdriver.Chrome('C:/Users/aduser01/chromedriver.exe')\n",
    "\n",
    "#find all departments that are finally chosen\n",
    "for depCode in depCode_list:\n",
    "    driver.get('https://www.com.tw/cross/check_%s_NO_1_108_0_3.html'% (depCode))\n",
    "    time.sleep(5)  #the first time: since the website will delay 5 seconds\n",
    "    html = driver.page_source\n",
    "    print(depCode)   \n",
    "    \n",
    "    elem = driver.find_elements_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr/td[5]//*[@src=\"images/putdep1.png\"]') \n",
    "    #print(len(elem))\n",
    "\n",
    "    #選擇學校之編號(in url)\n",
    "    school_chosen = driver.find_elements_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr/td[5]//*[@src=\"images/putdep1.png\"]/../../..//a')\n",
    "    #學生代碼 \n",
    "    code = driver.find_elements_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr/td[5]//*[@src=\"images/putdep1.png\"]/../../../../../../../../../td[3]')\n",
    "\n",
    "    for i in range(len(elem)):\n",
    "        #print (school_chosen[i].get_attribute('href'))\n",
    "        sch_id = school_chosen[i].get_attribute('href')\n",
    "        sch_id = sch_id[31:37]\n",
    "        #print(sch_id)\n",
    "\n",
    "        #print(code[i].text )\n",
    "        if code[i].text[0] == '8':\n",
    "            stu_code = code[i].text[0:6] \n",
    "        else:\n",
    "            stu_code = code[i].text[0:8]   \n",
    "        #print(stu_code) \n",
    "\n",
    "        #f3.write(\"%s,%s\\n\" % (sch_id ,stu_code)) \n",
    "        \n",
    "\n",
    "        sheet.append([sch_id, stu_code, \"\\n\"])\n",
    "\n",
    "\n",
    "wb.save(r'crawler_output/選擇學校.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10151609\n",
      "考區 : 國立新竹女中\n",
      "國立新竹女中\n"
     ]
    }
   ],
   "source": [
    "#test done\n",
    "school_id = driver.find_element_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr')\n",
    "school_id.text[4:10]\n",
    "\n",
    "\n",
    "x = driver.find_element_by_xpath('//*[@class=\"homepagetitle\"]/../table[1]/tbody/tr[5]/td[3]')  #學號 & 考區\n",
    "print(x.text)\n",
    "\n",
    "stu_code = x.text[14:]\n",
    "print(stu_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
